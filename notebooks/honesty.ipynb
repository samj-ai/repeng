{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a8371a-45af-4751-95d6-fc6f6d832414",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8271b6c6-1e75-4216-a791-8c7aa1e9f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ff222-553c-43ea-bdf5-ead31e2bcb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e8e3b079264f1dbbf3cd2db8b6ddda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29142dc3145a4261a32743d458ece90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a835ada91184776b974d00bb60e3db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab03d68d7e54d81b220fb269afd545a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774a9978989c46c981cf438548b567e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7114c3a850449a19b71f0ae36cd1a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d717c85c587c469f94e6e8518f44ebc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samjohnson/miniconda3/envs/repeng/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96b7ba8355943b091c02ab882724ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1d0a5330964bc49712eebdb9d3cf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf5e1e2cc0f4493b1568b9eeac6a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c4a147c75f46f3a0e48fb0b521812d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# note: can manually use the \n",
    "import os\n",
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"NEVER_PUT_THE_TOKEN_IN_CODE\"\n",
    "\n",
    "# Now load the model\n",
    "# since use_auth_token is set to True, it will pick up the token from the environment.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", \n",
    "    use_auth_token=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", \n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "# Test the model (this is just a placeholder for actual usage)\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c88046-ade7-4087-90bb-21851cbdcaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fcb93a66a8473ebdf5c67076ae9562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=True\n",
    ")\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    token=True\n",
    ")\n",
    "model = model.to(\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps:0\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "model = ControlModel(model, list(range(-5, -18, -1)))\n",
    "\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b133bde7-09d4-4ed1-84ac-c8fbd5c1b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The\n",
      "dataset[0].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The\n",
      "dataset[1].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The Earth\n",
      "dataset[1].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The Earth\n",
      "dataset[2].positive: [INST] Pretend you're an honest person making statements about the world. [/INST] The Earth'\n",
      "dataset[2].negative: [INST] Pretend you're an untruthful person making statements about the world. [/INST] The Earth'\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/true_facts.json\") as f:\n",
    "    suffixes = json.load(f)\n",
    "\n",
    "# see the emotion notebook for more details about this\n",
    "positive_personas = [\"honest\"]\n",
    "negative_personas = [\"untruthful\"]\n",
    "\n",
    "\n",
    "def template(persona: str, suffix: str) -> str:\n",
    "    return f\"{user_tag} Pretend you're an {persona} person making statements about the world. {asst_tag} {suffix}\"\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for suffix in suffixes:\n",
    "    tokens = tokenizer.tokenize(suffix)\n",
    "    for i in range(1, len(tokens) - 5):\n",
    "        truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "        for positive_persona, negative_persona in zip(\n",
    "            positive_personas, negative_personas\n",
    "        ):\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated),\n",
    "                    negative=template(negative_persona, truncated),\n",
    "                )\n",
    "            )\n",
    "\n",
    "# print some example entries\n",
    "for i in range(3):\n",
    "    print(f\"dataset[{i}].positive:\", dataset[i].positive)\n",
    "    print(f\"dataset[{i}].negative:\", dataset[i].negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd1a631-4195-4131-b3d8-581e4af52f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 147/147 [2:42:14<00:00, 66.22s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 31/31 [00:04<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset()  # make sure you always reset the model before training a new vector\n",
    "control_vector = ControlVector.train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1e142-a2f0-4c6b-bae3-a9f16b1c74bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==baseline\n"
     ]
    }
   ],
   "source": [
    "# the question to ask the modified model\n",
    "# don't forget the space after {user_tag} and before {asst_tag}!\n",
    "input = f\"{user_tag} You are late for work because party until very late last night, but you don't want to lose your job. What would you tell your boss instead? {asst_tag}\"\n",
    "\n",
    "# tokenizer and generation settings\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,  # silence warning\n",
    "    \"do_sample\": False,  # temperature=0\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"repetition_penalty\": 1.1,  # reduce control jank\n",
    "}\n",
    "\n",
    "print(\"==baseline\")\n",
    "model.reset()\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n++control\")\n",
    "# add the control vector with a certain strength (try increasing or decreasing this!)\n",
    "model.set_control(control_vector, 2)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "\n",
    "print(\"\\n--control\")\n",
    "# subtract the control vector, giving the opposite result (e.g. sad instead of happy)\n",
    "# depending on your vector, you may need more or less negative strength to match the positive effect\n",
    "model.set_control(control_vector, -2)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25d41e-8d9a-47f9-b018-d6ab6af7ea36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (repeng)",
   "language": "python",
   "name": "repeng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
